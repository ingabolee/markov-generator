{"cells":[{"cell_type":"markdown","metadata":{"id":"0cR5eVueFXUo"},"source":["## Markov Text Generator\n","\n","Random text generation with a simple Markov language model"]},{"cell_type":"markdown","metadata":{"id":"tRoJnhRLFXUz"},"source":["### What is a Markov chain?\n","\n","- A Markov chain is a stochastic process\n","- Markov chains use an internal state model to judge the probability of any state based on the current state\n","- Markov chains have the Markov property: The prediction depends only on the current state.\n","\n","Now, let's build a simple text generator. We want to predict the most probable next word, based on a limited set of current words."]},{"cell_type":"markdown","metadata":{"id":"HjS8I5kVFXU1"},"source":["## The implementation\n","\n","Let's start with a few basics. We'll use `random` to randomize output, and `pathlib.Path` to access text files. The function `sys.getsizeof` is used later to evaluate memory requirements of our language model. Finally, `matplotlib` is used to visualize experimental results, later on. **Note:** You might have to install matplotlib on your system, first, using pip (or similar)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"8p5ZHFMXFXU3","executionInfo":{"status":"ok","timestamp":1712670275831,"user_tz":-120,"elapsed":286,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}}},"outputs":[],"source":["import random\n","from pathlib import Path\n","from sys import getsizeof\n","%matplotlib notebook\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"NIJDK75cFXU5"},"source":["### 1. Preparing the text\n","\n","First, select an appropriate data set. You'll want a file of plain text. Potentially you'll have to preprocess whatever data you choose to operate on.\n","\n","#### Task\n","\n","Find a data set online, prepare it as raw ASCII text, and load it in the code block below."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rjOQuvxUFXU6","executionInfo":{"status":"ok","timestamp":1712670281936,"user_tz":-120,"elapsed":289,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}}},"outputs":[],"source":["text_file = Path('/content/data.txt')"]},{"cell_type":"markdown","metadata":{"id":"4EwKNE2zFXU7"},"source":["Next, you'll need a function **_file_to_words_**, which reads the `text_file` above and produces a list of words from the file. This is used as training data, to build the language model.\n","\n","#### Task\n","\n","Complete the function below appropriately."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2O4FhfBCFXU8","executionInfo":{"status":"ok","timestamp":1712670599071,"user_tz":-120,"elapsed":269,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}},"outputId":"fdd72a69-fbad-4f5f-d6b9-62be9d81e14d"},"outputs":[{"output_type":"stream","name":"stdout","text":["First 100 words:\n","['Main', 'menu', 'WikipediaThe', 'Free', 'Encyclopedia', 'Search', 'Wikipedia', 'Search', 'Create', 'account', 'Log', 'in', 'Personal', 'tools', 'Contents', 'hide', '(Top)', '2016', 'election', 'Transition', 'period,', 'inauguration,', 'and', 'first', '100', 'days', 'Administration', 'Toggle', 'Administration', 'subsection', 'Judicial', 'appointments', 'Toggle', 'Judicial', 'appointments', 'subsection', 'Leadership', 'style', 'Toggle', 'Leadership', 'style', 'subsection', 'Domestic', 'affairs', 'Toggle', 'Domestic', 'affairs', 'subsection', 'Foreign', 'affairs', 'Toggle', 'Foreign', 'affairs', 'subsection', 'Russia', 'and', 'related', 'investigations', 'Toggle', 'Russia', 'and', 'related', 'investigations', 'subsection', 'Ethics', 'Toggle', 'Ethics', 'subsection', 'Elections', 'during', 'the', 'Trump', 'presidency', 'Toggle', 'Elections', 'during', 'the', 'Trump', 'presidency', 'subsection', 'Historical', 'evaluations', 'and', 'public', 'opinion', 'See', 'also', 'References', 'Further', 'reading', 'Toggle', 'Further', 'reading', 'subsection', 'External', 'links', 'Presidency', 'of', 'Donald', 'Trump']\n"]}],"source":["def file_to_words(file: Path):\n","    with file.open(mode='rt', encoding='utf-8') as f:\n","        return f.read().split()\n","\n","\n","try:\n","    words = file_to_words(text_file)\n","except Exception as e:\n","    print(\"Something is wrong with your file\")\n","    print(e)\n","else:\n","    print(\"First 100 words:\")\n","    print(words[:100])"]},{"cell_type":"markdown","metadata":{"id":"IDHOLxPhFXU-"},"source":["### 2. Tuples: Groups of words\n","\n","While we have the text subdivided into words now, we want to experiment with various context windows. For that, we need to group words into tuples. Since we want to experiment with the context window, the next function should be generic, taking the size of the context window as a parameter.\n","\n","#### Example\n","\n","The sentence \"What a lovely day in February\" (6 words) split with a context window of three yields four tuples:\n","\n","- (What, a, lovely)\n","- (a, lovely, day)\n","- (lovely, day, in)\n","- (day, in, February)\n","\n","**Note:** The last word is later on going to be the predicted word. So, if we split with a window size of three, here, we will later on have a context window of only two words (the third word being the predicted one).\n","\n","#### Task\n","\n","Complete the function below."]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoTF3fYxFXU_","executionInfo":{"status":"ok","timestamp":1712677158556,"user_tz":-120,"elapsed":266,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}},"outputId":"eeb6c196-f940-4453-e0d2-eb285577e932"},"outputs":[{"output_type":"stream","name":"stdout","text":["('What', 'a', 'lovely')\n","('a', 'lovely', 'day', 'in')\n"]}],"source":["def tuples(words, window_size):\n","    \"\"\"Generates tuples from the given data string.\n","    So if our string was \"What a lovely day\", we'd generate\n","    (What, a, lovely) and then (a, lovely, day).\n","    \"\"\"\n","    tuples_list = []\n","    for i in range(len(words) - window_size + 1):\n","        tuple_item = tuple(words[i:i+window_size])\n","        tuples_list.append(tuple_item)\n","    return tuples_list\n","\n","test_sentence = \"What a lovely day in February\".split()\n","data = list(tuples(test_sentence, 3))[0]\n","assert(data == ('What', 'a', 'lovely'))\n","data = list(tuples(test_sentence, 4))[1]\n","assert(data == ('a', 'lovely', 'day', 'in'))\n"]},{"cell_type":"markdown","metadata":{"id":"6GqAUHlVFXVA"},"source":["### 3. A primitive database\n","\n","We will create a primitive database to create the Markov chain from the tuples we just got. We'll use a Python dictionary for that. A dictionary can be used as an adjacency list, where the key is the current node and the value is a list of nodes adjacent to the current node.\n","\n","#### Example\n","\n","The sentence \"I like coffee, I like tea\" with a context of one word would produce the following dictionary:\n","```\n","{\n","  ('I'): [('like')],\n","  ('like'): [('coffee,'), ('tea')],\n","  ('coffee,'): [('I')],\n","  ('tea'): [],\n","}\n","```\n","\n","**Note:** You will have to capture the probabilities of the next node. There's multiple ways of implementing this. Consider, how you will do it, then proceed with your implementation.\n","\n","#### Task\n","\n","Complete the following function."]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eiQ_lApZFXVB","executionInfo":{"status":"ok","timestamp":1712679334781,"user_tz":-120,"elapsed":307,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}},"outputId":"24da6ef9-0475-4b7b-f0d5-ba2549dbfe54"},"outputs":[{"output_type":"stream","name":"stdout","text":["{('I',): ['like', 'like'], ('like',): ['coffee,', 'tea'], ('coffee,',): ['I']}\n"]}],"source":["def generate_database(data):\n","  result = {}\n","  for t in data:\n","    l = list (t)\n","    key = tuple(l[:-1])\n","    word = l[-1]\n","    if key in result:\n","      result [key].append(word)\n","    else:\n","      result[key] = [word]\n","  return result\n","\n","\n","test_sentence = \"I like coffee, I like tea\".split()\n","data = list(tuples(test_sentence, 2))\n","database = generate_database(data)\n","print (database)\n","assert(('tea') in database[('like' ,)])\n"]},{"cell_type":"markdown","metadata":{"id":"1ewnJwuyFXVB"},"source":["### 4. Markov text generation\n","\n","Now, let's generate some text. Based on a prompt, we will predict next tokens repeatedly, until either a certain amount of text is produced, or the chain reaches an end (i.e., a token with no follow-up tokens).\n","\n","#### Task\n","\n","Complete the following function"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A1TFEU02FXVC","executionInfo":{"status":"ok","timestamp":1712679844050,"user_tz":-120,"elapsed":648,"user":{"displayName":"Kelvin Abrokwaah Twum","userId":"08790061877348915729"}},"outputId":"a6e11e87-3e07-4c05-cb6f-b137b3c60617"},"outputs":[{"output_type":"stream","name":"stdout","text":["rank his presidency as one of the worst in American history. 2016 election Main articles: Donald Trump on social media and Donald Trump sexual misconduct allegations The Trump administration ignored detailed plans on how to mass-produce protective respirator masks under a program that had been launched by the Obama administration "]}],"source":["def generate_markov_text(prompt: str, database: dict, text_size: int = 50):\n","  front = prompt.split()[-3:]\n","  while text_size > 0:\n","    t=tuple(front)\n","    word=random.choice(database[t])\n","    front.pop(0)\n","    front.append(word)\n","    text_size-=1\n","    yield word\n","\n","words = file_to_words(text_file)\n","data=tuples(list(words), 4)\n","database = generate_database(data)\n","prompt = \"and scholars and historians\"\n","\n","for word in generate_markov_text(prompt, database):\n","    print(word, end=' ')"]},{"cell_type":"markdown","metadata":{"id":"RpqZI_3tFXVD"},"source":["### 5. Experimentation\n","\n","Now, let's investigate further.\n","\n","#### Task\n","\n","Use the `getsizeof` function to compare memory requirements for various context windows. Experiment with context windows between 1+1 and 20+1 (the \"+1\" being the predicted next word, respectively). Use `matplotlib` to draw a bar chart of memory requirements based on the training text data you are using."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1TehniuFXVD"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[{"file_id":"1cCZWvPLNS2dqdx5HeydvxXqi08WUE7G7","timestamp":1712679907962}]}},"nbformat":4,"nbformat_minor":0}